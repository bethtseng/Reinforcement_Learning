{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceInvaders-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, merge, Permute, Conv2D\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.callbacks import History\n",
    "import keras\n",
    "import os\n",
    "\n",
    "from collections import deque\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self._state_size = state_size\n",
    "        self._action_size = action_size        \n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.99    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.8#0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self._learning_rate = 0.001\n",
    "        self.model_name = 'Breakout-DQN.h5'\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "    \n",
    "    \n",
    "    def _build_model(self, hidden_size=24):\n",
    "            \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), input_shape=self._state_size))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(self._action_size))\n",
    "        model.add(Activation('linear'))\n",
    "        print(model.summary())\n",
    "\n",
    "        opt = Adam(lr=self._learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "        model.summary()\n",
    "        \n",
    "        if os.path.exists(self.model_name):\n",
    "            model.load_weights(self.model_name)\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        state = state.reshape(1,210, 160, 3)\n",
    "        next_state = next_state.reshape(1,210, 160, 3)\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def update_target_model(self):\n",
    "        self.target_model = self.model\n",
    "        \n",
    "    def train_model(self, batch_size=20):\n",
    "        def batch(iterable, n=1):\n",
    "            l = len(iterable)\n",
    "            for ndx in range(0, l, n):\n",
    "                yield list(itertools.islice(iterable, ndx, min(ndx + n, l)))\n",
    "        \n",
    "        history = History()\n",
    "        batch_data = list(batch(self.memory, batch_size))\n",
    "        selected_batch = random.sample(batch_data, 1)\n",
    "        \n",
    "        for state, action, reward, next_state, done in selected_batch[0]:\n",
    "            target = self.model.predict(state)\n",
    "            target_val = self.model.predict(next_state)\n",
    "            target_val_ = self.target_model.predict(next_state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                a = np.argmax(target_val)\n",
    "                target[0][action] = reward + self.gamma * target_val_[0][a]\n",
    "            \n",
    "            self.model.fit(state, target, epochs=1, verbose=0, callbacks=[history])\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay    \n",
    "\n",
    "    def takeAction(self, state):\n",
    "        state = state.reshape(1,210, 160, 3)\n",
    "        act = np.argmax(self.model.predict(state))\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            act = random.randrange(self._action_size)\n",
    "        return act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 51, 39, 32)        6176      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 51, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 24, 18, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 24, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 22, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 22, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               11534848  \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 11,612,836\n",
      "Trainable params: 11,612,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 51, 39, 32)        6176      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 51, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 24, 18, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 24, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 22, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 22, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               11534848  \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 11,612,836\n",
      "Trainable params: 11,612,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 51, 39, 32)        6176      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 51, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 24, 18, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 24, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 22, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               11534848  \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 11,612,836\n",
      "Trainable params: 11,612,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 51, 39, 32)        6176      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 51, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 24, 18, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 24, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 22, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               11534848  \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 11,612,836\n",
      "Trainable params: 11,612,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Episode: 0, Total Reward: 2.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bed1d2323643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mshows\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dc9e105ac2e0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mtarget_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mtarget_val_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuting_data/github/openAI/.venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/yuting_data/github/openAI/.venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuting_data/github/openAI/.venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuting_data/github/openAI/.venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuting_data/github/openAI/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 10000\n",
    "render = True\n",
    "shows = 10\n",
    "total_reward = list()\n",
    "\n",
    "env = gym.make('Breakout-v0')\n",
    "agent = DQNAgent(env.observation_space.shape, env.action_space.n)\n",
    "\n",
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    \n",
    "    rewards = 0\n",
    "    while True:\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "        action = agent.takeAction(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        rewards += reward\n",
    "        \n",
    "        \n",
    "        if done:\n",
    "            total_reward.append(rewards)\n",
    "#             print(\"Episode: {}, Total Reward: {}\".format(e, rewards))\n",
    "            if rewards <= 1:\n",
    "                agent.remember(state, action, rewards-np.mean(total_reward[-shows:]), next_state, done)\n",
    "                state = next_state\n",
    "            break\n",
    "        else:\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            \n",
    "    agent.train_model(32)\n",
    "    \n",
    "    if e % shows == 0:\n",
    "        print(\"Episode: {}, Total Reward: {}\".format(e, np.mean(total_reward[-shows:])))\n",
    "        agent.update_target_model()\n",
    "        agent.model.save_weights(agent.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py36(openAI gym)",
   "language": "python",
   "name": "openai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
